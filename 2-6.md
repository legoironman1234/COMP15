## `unit_test` and Makefiles
- Put this in for unit tests in the makefile
- Do not need to do `make unit_test`, just `unit_test` works
```
unit_test: unit_test_driver.o [list .o files used in tests]
	${CXX} $^
```
## Computational complexity
- Pretty important for the rest of computer science
- Precisely describes the time and space performance
	- **Time complexity:** how long it takes a program to run
	- **Space complexity:** how much memory a program takes to run
- Models the resource requirements of an algorithm (time, space, etc.) in terms of *input size*
- ==For today, just time complexity==
### Measuring time?
- Nothing to do with the literal computational time
	- This number can vary per each run
- Count the number of *elementary operations* that run
	- *elementary operations:* ==considered constant time, variation between these operations in compute time is negligible==
		- Variable declarations `int x`
		- Assignment of primitives `x = 10`
			- e.g. an assignment of two objects in a class is not as fast
		- Comparison of primitives `x < y`
		- Others `x + y`
### Asymptotic analysis
- Not interested in the performance for small inputs, but what changes as input size grows
	- ==The growth rate of the number of operations==
### Big O Notation
- The upper bound of a function as it approaches infinity
- $c\cdot g(n)$ is an upper bound on $f(n)$
	- $f(n) = 2n + 1$ and $g(n) = 3n$ 
	- $f(n) = n^2$ and there is no $c$ s.t. a linear function can bound $f(n)$
- Care about tightest upper bound
- ==Throw away all the constants, and find the "biggest factor"==
### Complexity classes
- $O(1)$: constant
	- Best case scenario: algorithm will always take same amount of time to work
- $O(\log n)$: logarithm
	- Very large input, but still small number of operations
	- Almost as good as constant time
	- Repeatedly cutting something in half (base 2)
- $O(n)$: linear
	- Have to go through every element
- $O(n^2)$: quadratic
	- two for lops
- $O(n^k)$: polynomial
- $O(2^n)$: exponential
	- Worst case scenario: algorithm is not feasible to run

#### Conditional complexity
- Unless it's specified, we use the worst case complexity (meaning conditionals are discounted)
- Sometimes *it is* specified (e.g. best, average, worst)
	- average and worst case are not *always* the same

### Limitations
- Dropping the constants and other factors
	- Might lose some precision when comparing within a complexity class

### Example: AL(already expanded) vs LL (back ptr)
- Insert at front
	- AL: $O(n)$
	- LL: $O(1)$
- Insert at back
	- AL: $O(1)$
	- LL: $O(1)$
- Get kth element
	- AL: $O(1)$
	- LL: $O(n)$
- Check if given element is in list
	- AL:$O(n)$
	- LL: $O(n)$
**amortized analysis:** operations like AL expansion happen in the long run and average to $O(1)$

## Others
Big $\Omega$: lower bounds
Big $\Theta$: both upper and lower bounds


