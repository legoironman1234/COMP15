
# Midterm Questions

- ~~How to count height of a node?~~
	- ~~Just count the edges
		- ~~height(leaf) = 0, height(empty tree) = -1
	- ~~Does the height(root) == depth?
		- ~~Yes, but in a
- ~~Zip a Linked List~~
	- ~~See the midterm review on notability
- ~~Queue with 2 stacks~~
	- ~~See the midterm review on notability
- ~~How is AVL::insert $O(\log n)$ if you have to do unbalanced insert?
		- Unbalanced insert is based on height of tree (which is guaranteed to be diminishing in AVL) so it is $O(\log n)$~~


# Midterm Cheat Sheet
~~- Data structure method complexities (copy from slides, with assumptions)
- ~~Pseudocode for some operations (recursive especially)
	- ~~Breadth first traversal code
	- ~~Order traversals of tree all try to handle empty as a base cse~~
- ~~AVL Rotations/Balancing~~
- ==TODO:== Binary tree excercises
	- ~~`numLeaves(node)`: count number of leaves in the tree rooted at node~~
	- `concatLeaves(node)`: For a tree rooted at node that stores strings, return the concatenation of all strings stored in the leaves of the tree only
	- `pathToValue(node,val)`: return “” if val is not in tree, otherwise return directions, like “went left, went right, went right, went left, found it!” (Don’t worry about punctuation and spacing — can just return a string like “LRRLTarget” where Target is the item we’re looking for.)
- ~~Size of Huffman encoding
	- ~~Just add properly!~~

# Actual Review

## Types, ADT, and Data Structures

- ~~Type is name for a set of values
- ~~ADT is model for a type
- ~~Data structure for organizing and storing data

## Lists

- ~~Ordered collection of element
- ~~Size varies
- ~~Know methods of lists~~
- ~~Complexities of AL vs LL operations
	- ~~elementAt is more expensive in LL~~

## Aside
- ~~Know wrapper/helper paradigm

## Complexity Analysis
- ~~Focus on **asymptotic analysis**

## Queues
- ~~FIFO
- ~~Know operations on queues

## Stacks
- ~~LIFO
- ~~Know operations on stacks

## Binary Search
- ~~Sorted AL $\implies$ Binary Search
	- ~~LL you have to iterate to middle $O(n)$ ! ** $\therefore$cannot use LL for binary search **
- ~~A sorted AL is **worse** than a BST, because to insert (especially at front of list) is **still** $O(n)$
	- ~~In bushy BST, search and adding are $O(\log n)$

## Sets
- Unordered, duplicate-free collection of elements
- Know operations
	- especially `union`, `intersection`, `subtract`, `isSubset`
- Either implemented using BSTs (ordered) or hashes (unordered). These are the **data structures** the set is the **ADT** 

## Trees
~~- Each node can now point to 1 or more node
- ~~One parent per node, except root
- ~~==KNOW TREE VOCAB== (height, depth, internal node, etc.)
- ~~Three types of traversals, ==PRACTICE TREE TRAVERSAL ORDERS==
	- ~~in order
	- ~~pre order
	- ~~post order
	- ~~depth first (the above three)
	- ~~level order (breadth-first)~~

## BSTs
~~https://www.cs.tufts.edu/comp/15/schedule/lectures/bsts/bst_intro.pdf ~~
- ~~Invariants
	- ~~find the conditions
- ~~contains, min, insert~~, ~~==remove== operations depends on height of tree
	- ~~In general worst case, $O(n)$ , but we wanted bushy/balanced tree with operations being $O(\log n)$
- ~~DS for finite map ADT bc efficient search
- ~~depth![[Screenshot 2023-03-13 at 6.05.25 PM.jpg]]
- ~~dist
```c++

int BST:dist(BSTNode *nodep, int key) {
	if (high < nodep->key) 
	// based on assumption that low < high
    // both high and low are in left subtree
    return dist(nodep->left, low, high);
  else if (low > nodep->key)
    // both high and low are in right subtree
    return dist(nodep->right, low, high);
  else
    // this is where we “split”
    //lowest common ancestor case
    return depth(nodep, low)+depth(nodep, high);
}
```


## AVLs
- ~~See notability March 13, 2023 (3) for notes
### Steps to create an instance from a given set
1. ~~Naive insert and demarcate touched nodes
2. ~~~~Do rotate at first out of balance node
4. ~~Check subtree balances of new instance (sanity check!)~~


